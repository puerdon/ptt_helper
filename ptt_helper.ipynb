{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 方便撈取的ptt語料的指令：\n",
    "\n",
    "## `list_{檔案副檔名}`: 列出各版各年份有幾篇\n",
    "\n",
    "`\n",
    "$ python3 ptt_helper.py list_json|list_vrt -d <data_directory> (-b <board_name>)\n",
    "`\n",
    "\n",
    "若不指定<board_name>，則列出<data_directory>下各個版的資料夾中，各年份的文章有幾篇。\n",
    "若指定<board_name>，則只列出<data_directory>/<board_name>下各年份的文章有幾篇。\n",
    "\n",
    "\n",
    "\n",
    "## `get_latest_post_timestamp`: 列出某板最新貼文時間\n",
    "`\n",
    "$ python3 ptt_helper.py get_latest_post_timestamp -d <data_directory> -b <board_name> \n",
    "`\n",
    "\n",
    "找出路徑<data_directory>/<board_name>中，離現在最近的文章的timestamp。（用來動態更新爬蟲時，確定哪些時間的文章是還沒有的。）\n",
    "\n",
    "\n",
    "## `html2json`: 將 .html 轉成 .json\n",
    "`\n",
    "$ python3 ptt_helper.py html2json -d <data_directory> (-b <board_name>) (--use-mp)\n",
    "`\n",
    "\n",
    "把<data_directory>下所有的文章的.html檔都改成json檔。（原本我的爬蟲是存成.html格式，後來發現這樣多佔用了很多空間。）\n",
    "\n",
    "`--use-mp`: 啟動多進程模式\n",
    "\n",
    "\n",
    "## `json2vrt`: 將 .json 轉成一個 .vrt [耗時因為斷詞]\n",
    "`\n",
    "$ python3 ptt_helper.py json2vrt -d <json檔所在資料夾> --use-mp\n",
    "`\n",
    "\n",
    "## `ws`: 測試斷詞\n",
    "`\n",
    "$ python3 ptt_helper.py ws <json_file_path>\n",
    "`\n",
    "\n",
    "斷詞\n",
    "\n",
    "\n",
    "## `dynamic_crawl`: 動態更新ptt語料\n",
    "\n",
    "`\n",
    "$ python3 ptt_helper.py dynamic_crawl -d <json檔所在資料夾>\n",
    "`\n",
    "\n",
    "## `reduce_to_one_vrt`: 將一個版的所有貼文的.vrt整合成一個.vrt\n",
    "\n",
    "`\n",
    "python3 ptt_helper.py reduce_to_one_vrt -d <個別.vrt檔所在資料夾> -o <要輸出.vrt的資料夾>\n",
    "`\n",
    "\n",
    "## `save_lexical_items_to_mongo`: 掃過vrt，把詞彙資訊整理到mongodb中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import traceback\n",
    "import sys\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import timeit\n",
    "import logging\n",
    "import multiprocessing as mp\n",
    "# from pymongo import MongoClient\n",
    "\n",
    "from ckipws import CKIP\n",
    "from html2json import html2json, html2json_wrapper\n",
    "from json2tei import json2tei, json2tei_wrapper\n",
    "\n",
    "\n",
    "# import libtmux\n",
    "# from pyquery import PyQuery\n",
    "# from html.parser import HTMLParser\n",
    "\n",
    "# from html2vrt_new import parse_content\n",
    "# from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `list`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_by_board_by_year(data_dir=None, board_name=None, ext=\"json\"):\n",
    "    \n",
    "    if board_name is None:\n",
    "\n",
    "        for board_dir in data_dir.iterdir():\n",
    "            if board_dir.is_dir():\n",
    "                print(f\"[版名: {board_dir.name}]\")\n",
    "                \n",
    "                iterate_year_dir_in_a_board_dir(board_dir, ext=ext)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(f\"[{board_name}版]\")\n",
    "        iterate_year_dir_in_a_board_dir(data_dir / board_name, ext=ext)  \n",
    "\n",
    "\n",
    "def iterate_year_dir_in_a_board_dir(board_dir, ext=\"json\"):\n",
    "#     total = 0\n",
    "#     total_of_a_year = 0\n",
    "    \n",
    "    results = []\n",
    "    # results 為 list of (int, int)\n",
    "    \n",
    "    for year_dir in board_dir.iterdir():\n",
    "\n",
    "        if year_dir.is_file():\n",
    "            continue\n",
    "        \n",
    "\n",
    "        total_of_a_year = len([p for p in year_dir.iterdir() if p.suffix ==  f\".{ext}\"])   \n",
    "        results.append((int(year_dir.name), total_of_a_year))\n",
    "\n",
    "    \n",
    "    # 按照年份分類    \n",
    "    results.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # 算每一年的加總\n",
    "    total = sum(number for (_, number) in results)\n",
    "        \n",
    "    for year, n in results:\n",
    "        print(f\"-- {year} 年: {n} 篇\")\n",
    "    print(f\"----\\n總計: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  `get_latest_post_timestamp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_post_timestamp(data_dir, board_name):\n",
    "    \n",
    "    board_dir = data_dir / board_name\n",
    "    \n",
    "    # step 0: 檢查 data_dir 和 board 存不存在\n",
    "    if not data_dir.is_dir() or not board_dir.is_dir():\n",
    "        raise FileNotFoundError\n",
    "        # TBD: 要給出錯誤訊息\n",
    "\n",
    "    # step 1: 先找出該版中，存在本地中最新的資料\n",
    "    latest_year = max([int(year.name) for year in board_dir.iterdir()])\n",
    "    latest_year_dir = board_dir / str(latest_year)\n",
    "    latest_timestamp = max([int(t.name[16:16+10]) for t in latest_year_dir.iterdir()])\n",
    "\n",
    "    return latest_timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `json2vrt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_not_chinese_char(char):\n",
    "    \"\"\"\n",
    "    Python port of Moses' code to check for CJK character.\n",
    "\n",
    "    :param character: The character that needs to be checked.\n",
    "    :type character: char\n",
    "    :return: bool\n",
    "    \"\"\"\n",
    "    return not (19968 <= ord(char) <= 40869)\n",
    "\n",
    "def no_chinese_char_at_all(string):\n",
    "    return all(map(is_not_chinese_char, string))\n",
    "\n",
    "def _preprocessing_content(string):\n",
    "    \"\"\"\n",
    "    將ptt內文作為字串，篩掉那些非中文字，並回傳真正要丟入斷詞的list of strings\n",
    "    Input: content string\n",
    "    Output: list of valid string\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    for sentence in string.split():\n",
    "        if not no_chinese_char_at_all(sentence.strip()):\n",
    "            result.append(sentence.strip())\n",
    "    return result\n",
    "\n",
    "\n",
    "def _seg_and_pos(list_of_sentences):\n",
    "    \"\"\"\n",
    "    input: <List of String>\n",
    "    [\"我每天都在睡覺\", \"好喜歡寫程式\"]\n",
    "    \n",
    "\n",
    "    output: <List of List of (Str, Str)>\n",
    "    [\n",
    "        [\n",
    "            ('我', 'Nb'),\n",
    "            ('每天', 'P'),\n",
    "            ...\n",
    "        ],\n",
    "        [\n",
    "            ('好', 'D'),\n",
    "            ('喜歡', 'V')\n",
    "        ]\n",
    "    ]\n",
    "    \"\"\"\n",
    "#     result = list()\n",
    "#     word_sentence_list = ws(\n",
    "#         list_of_strings,\n",
    "#         sentence_segmentation=True,\n",
    "#     )\n",
    "#     pos_sentence_list = pos(word_sentence_list)\n",
    "#     for i, (list_of_word, list_of_pos) in enumerate(zip(word_sentence_list, pos_sentence_list)):\n",
    "#         result.append(list())\n",
    "#         for w, p in zip(list_of_word, list_of_pos):\n",
    "#             result[i].append((w, p))\n",
    "#     return result\n",
    "\n",
    "    global ckipws\n",
    "\n",
    "    list_of_segmented_sentences = None\n",
    "    result = []\n",
    "    \n",
    "    # 先檢查輸入的list中，是否有空字串的元素\n",
    "\n",
    "    indexs = []\n",
    "    ls = map(str.strip, list_of_sentences)\n",
    "    for i, elm in enumerate(ls):\n",
    "        if not elm:  # 如果 elm 是 '' 空字串\n",
    "            indexs.append(i)\n",
    "    # 待會就用 len(indexs) 是否為 0 來判斷要不要後處理\n",
    "    # 因為如果 ['', '我我', ''] 丟進中研院的斷詞系統\n",
    "    # 回傳的結果會自動省略空字串變成 ['我(Nb)\\n']\n",
    "\n",
    "    try:\n",
    "        list_of_segmented_sentences = ckipws.ApplyList(list_of_sentences)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "    for segmented_sentence in list_of_segmented_sentences:\n",
    "        _r = []\n",
    "        for word_and_pos in segmented_sentence.strip().split('\\u3000'):\n",
    "            wp = word_and_pos.split(\"(\")\n",
    "            word = wp[0]\n",
    "            pos = wp[-1].strip().strip(\")\")\n",
    "            \n",
    "            if not word: # 偵測為 ( 的word\n",
    "                word = '('\n",
    "            \n",
    "            _r.append((word, pos))\n",
    "        result.append(_r)\n",
    "            \n",
    "            \n",
    "    if len(indexs) > 0:\n",
    "        for i in indexs:\n",
    "            result.insert(i, [(\"NULL\", \"NULL\")])\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def _render_tagged_tuple_to_string(list_of_list_of_tup, post_body=False):\n",
    "    \"\"\"\n",
    "    post_body: 如果是本文進來斷詞的話，因為本文是可以支援多行的，所以要在output時，要為每個句子的前後加上<s></s>\n",
    "    \n",
    "    Input: list of list of tuple\n",
    "    [\n",
    "        [\n",
    "            (\"我\", \"Nd\"),\n",
    "            (\"跑\", \"VA\"),\n",
    "            ...\n",
    "        ],\n",
    "        ...\n",
    "    ]\n",
    "     \n",
    "    Output: <str>\n",
    "    \n",
    "    我\\tNd\n",
    "    跑\\tVA\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    if len(list_of_list_of_tup) == 0:\n",
    "        return \"\"\n",
    "    elif len(list_of_list_of_tup) == 1:\n",
    "        # 如果是網址就不要出現\n",
    "        if list_of_list_of_tup[0][0][0].startswith(\"http\"):\n",
    "            return \"\"\n",
    "        return '\\n'.join((f\"{word}\\t{pos}\" for word, pos in list_of_list_of_tup[0]))\n",
    "    else:\n",
    "        result = \"\\n\"\n",
    "        for sentence in list_of_list_of_tup:\n",
    "            result += \"<s>\\n\"\n",
    "            for word, pos in sentence:\n",
    "                \n",
    "                \n",
    "                if word.startswith(\"http\"):\n",
    "                    continue\n",
    "                \n",
    "                if post_body:\n",
    "                    result += f\"{word}\\t{pos}\\n\"\n",
    "#                 s = '\\n'.join((f\"{word}\\t{pos}\" for word, pos in sentence))\n",
    "#                 result += '\\n<s>\\n' + s + '\\n</s>'\n",
    "                else:\n",
    "                    result += f\"{word}\\t{pos}\\n\"\n",
    "#                     s = '\\n'.join((f\"{word}\\t{pos}\" for word, pos in sentence))\n",
    "#                     result += s + '\\n'\n",
    "            result += \"</s>\\n\"\n",
    "                \n",
    "        return result\n",
    "\n",
    "\n",
    "def json2vrt(json_path):\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        structured_post = json.load(f)\n",
    "    \n",
    "    post_id = structured_post[\"post_id\"]\n",
    "    post_author = structured_post[\"post_author\"]\n",
    "    \n",
    "    if not isinstance(structured_post[\"post_time\"], int):\n",
    "        structured_post[\"post_time\"] = int(structured_post[\"post_time\"])\n",
    "    dt = datetime.fromtimestamp(structured_post[\"post_time\"])\n",
    "    \n",
    "    year = str(dt.year)\n",
    "    month = str(dt.month)\n",
    "    day = str(dt.day)\n",
    "    neg = str(structured_post[\"post_vote\"][\"neg\"])\n",
    "    pos = str(structured_post[\"post_vote\"][\"pos\"])\n",
    "    neu = str(structured_post[\"post_vote\"][\"neg\"])\n",
    "    \n",
    "    title_text = _render_tagged_tuple_to_string(_seg_and_pos([structured_post[\"post_title\"]]))\n",
    "    \n",
    "    body_text = _render_tagged_tuple_to_string(_seg_and_pos(_preprocessing_content(structured_post[\"post_body\"])), post_body=True)\n",
    "    \n",
    "    comments_text = \"\\n\"\n",
    "    if len(structured_post['comments']) != 0:\n",
    "        for c in structured_post['comments']:\n",
    "            comment_author = c[\"author\"]\n",
    "            comment_type = c[\"type\"]\n",
    "            comment_order = c[\"order\"]\n",
    "            comment_text = _render_tagged_tuple_to_string(_seg_and_pos([c[\"content\"]]))\n",
    "            comments_text += f\"\"\"\n",
    "<text id=\"{post_id.replace('.', '_')}_comment_{comment_order}\" type=\"comment\" author=\"{comment_author}\" c_type=\"{comment_type}\">\n",
    "<s>\n",
    "{comment_text}\n",
    "</s>\n",
    "</text>\n",
    "\"\"\"\n",
    "    \n",
    "    return f\"\"\"\n",
    "<post id=\"{post_id}\" year=\"{year}\" month=\"{month}\" day=\"{day}\" neg=\"{neg}\" pos=\"{pos}\" neu=\"{neu}\">\n",
    "<text id=\"{post_id.replace('.', '_')}_title\" type=\"title\" author=\"{post_author}\" c_type=\"NA\">\n",
    "<s>\n",
    "{title_text}\n",
    "</s>\n",
    "</text>\n",
    "<text id=\"{post_id.replace('.', '_')}_body\" type=\"body\" author=\"{post_author}\" c_type=\"NA\">\n",
    "{body_text}\n",
    "</text>\n",
    "{comments_text}\n",
    "</post>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json2vrt_wrapper(json_path):\n",
    "\n",
    "    logging.info(\"開始處理: %s\", json_path)\n",
    "\n",
    "    # 即將要產生的.vrt檔路徑\n",
    "    vrt_path = json_path.with_suffix(\".vrt\")\n",
    "\n",
    "    # 如果該資料夾已經有 .json 檔了就跳過\n",
    "    if vrt_path.is_file():\n",
    "        logging.info(\"-- 已存在vrt檔: %s\", vrt_path)\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        vrt_result = json2vrt(json_path)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"出問題檔案: {json_path}\")\n",
    "        print(f\"錯誤訊息: {e}\")\n",
    "        logging.error(\"-- 執行 json2vrt() 出問題\")\n",
    "        logging.error(\"-- 錯誤訊息: %s\", e)\n",
    "        error_class = e.__class__.__name__ #取得錯誤類型\n",
    "        detail = e.args[0] #取得詳細內容\n",
    "        cl, exc, tb = sys.exc_info() #取得Call Stack\n",
    "        lastCallStack = traceback.extract_tb(tb)[-1] #取得Call Stack的最後一筆資料\n",
    "        fileName = lastCallStack[0] #取得發生的檔案名稱\n",
    "        lineNum = lastCallStack[1] #取得發生的行號\n",
    "        funcName = lastCallStack[2] #取得發生的函數名稱\n",
    "        errMsg = \"File \\\"{}\\\", line {}, in {}: [{}] {}\".format(fileName, lineNum, funcName, error_class, detail)\n",
    "        print(errMsg)\n",
    "   \n",
    "    else:\n",
    "#         if json_result is None:\n",
    "#             logging.warning(\"-- 空白文!\")\n",
    "#             return\n",
    "\n",
    "        with vrt_path.open(\"w\") as f:\n",
    "            f.write(vrt_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `json2tei`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckip = CKIP(\"/home/don/CKIPWS_Linux\")\n",
    "\n",
    "# def is_not_chinese_char(char):\n",
    "#     \"\"\"\n",
    "#     Python port of Moses' code to check for CJK character.\n",
    "\n",
    "#     :param character: The character that needs to be checked.\n",
    "#     :type character: char\n",
    "#     :return: bool\n",
    "#     \"\"\"\n",
    "#     return not (19968 <= ord(char) <= 40869)\n",
    "\n",
    "# def no_chinese_char_at_all(string):\n",
    "#     return all(map(is_not_chinese_char, string))\n",
    "\n",
    "# def _preprocessing_content(string):\n",
    "#     \"\"\"\n",
    "#     將ptt內文作為字串，篩掉那些非中文字，並回傳真正要丟入斷詞的list of strings\n",
    "#     Input: content string\n",
    "#     Output: list of valid string\n",
    "#     \"\"\"\n",
    "#     result = []\n",
    "    \n",
    "#     for sentence in string.split():\n",
    "#         if not no_chinese_char_at_all(sentence.strip()):\n",
    "#             result.append(sentence.strip())\n",
    "#     return result\n",
    "\n",
    "\n",
    "# def _seg_and_pos(list_of_sentences, ckipws):\n",
    "#     \"\"\"\n",
    "#     input: <List of String>\n",
    "#     [\"我每天都在睡覺\", \"好喜歡寫程式\"]\n",
    "    \n",
    "\n",
    "#     output: <List of List of (Str, Str)>\n",
    "#     [\n",
    "#         [\n",
    "#             ('我', 'Nb'),\n",
    "#             ('每天', 'P'),\n",
    "#             ...\n",
    "#         ],\n",
    "#         [\n",
    "#             ('好', 'D'),\n",
    "#             ('喜歡', 'V')\n",
    "#         ]\n",
    "#     ]\n",
    "#     \"\"\"\n",
    "#     list_of_segmented_sentences = None\n",
    "#     result = []\n",
    "    \n",
    "#     # 先檢查輸入的list中，是否有空字串的元素\n",
    "\n",
    "#     indexs = []\n",
    "#     ls = map(str.strip, list_of_sentences)\n",
    "#     for i, elm in enumerate(ls):\n",
    "#         if not elm:  # 如果 elm 是 '' 空字串\n",
    "#             indexs.append(i)\n",
    "#     # 待會就用 len(indexs) 是否為 0 來判斷要不要後處理\n",
    "#     # 因為如果 ['', '我我', ''] 丟進中研院的斷詞系統\n",
    "#     # 回傳的結果會自動省略空字串變成 ['我(Nb)\\n']\n",
    "\n",
    "#     try:\n",
    "#         list_of_segmented_sentences = ckipws.ApplyList(list_of_sentences)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         return None\n",
    "    \n",
    "#     for segmented_sentence in list_of_segmented_sentences:\n",
    "#         _r = []\n",
    "#         for word_and_pos in segmented_sentence.strip().split('\\u3000'):\n",
    "#             wp = word_and_pos.split(\"(\")\n",
    "#             word = wp[0]\n",
    "#             pos = wp[-1].strip().strip(\")\")\n",
    "            \n",
    "#             if not word: # 偵測為 ( 的word\n",
    "#                 word = '('\n",
    "            \n",
    "#             _r.append((word, pos))\n",
    "#         result.append(_r)\n",
    "            \n",
    "#     del list_of_segmented_sentences\n",
    "    \n",
    "#     if len(indexs) > 0:\n",
    "#         for i in indexs:\n",
    "#             result.insert(i, [(\"NULL\", \"NULL\")])\n",
    "    \n",
    "#     return result\n",
    "\n",
    "\n",
    "# def _render_tagged_tuple_to_string(list_of_list_of_tup, post_body=False):\n",
    "#     \"\"\"\n",
    "#     post_body: 如果是本文進來斷詞的話，因為本文是可以支援多行的，所以要在output時，要為每個句子的前後加上<s></s>\n",
    "    \n",
    "#     Input: list of list of tuple\n",
    "#     [\n",
    "#         [\n",
    "#             (\"我\", \"Nd\"),\n",
    "#             (\"跑\", \"VA\"),\n",
    "#             ...\n",
    "#         ],\n",
    "#         ...\n",
    "#     ]\n",
    "     \n",
    "#     Output: <str>\n",
    "    \n",
    "#     我\\tNd\n",
    "#     跑\\tVA\n",
    "    \n",
    "#     \"\"\"\n",
    "    \n",
    "#     if len(list_of_list_of_tup) == 0:\n",
    "#         return \"\"\n",
    "#     elif len(list_of_list_of_tup) == 1:\n",
    "#         # 如果是網址就不要出現\n",
    "#         if list_of_list_of_tup[0][0][0].startswith(\"http\"):\n",
    "#             return \"\"\n",
    "#         return '\\n'.join((f'<w type=\"{pos}\">{word}</w>' for word, pos in list_of_list_of_tup[0]))\n",
    "#     else:\n",
    "#         result = \"\\n\"\n",
    "#         for sentence in list_of_list_of_tup:\n",
    "#             result += \"<s>\\n\"\n",
    "#             for word, pos in sentence:\n",
    "                \n",
    "                \n",
    "#                 if word.startswith(\"http\"):\n",
    "#                     continue\n",
    "                \n",
    "#                 if post_body:\n",
    "#                     result += f'                <w type=\"{pos}\">{word}</w>\\n'\n",
    "\n",
    "#                 else:\n",
    "#                     result += f'                <w type=\"{pos}\">{word}</w>\\n'\n",
    "\n",
    "#             result += \"</s>\\n\"\n",
    "                \n",
    "#         return result\n",
    "\n",
    "\n",
    "# def json2tei(json_path):\n",
    "#     global ckip\n",
    "#     with open(json_path, 'r') as f:\n",
    "#         structured_post = json.load(f)\n",
    "    \n",
    "#     post_id = structured_post[\"post_id\"]\n",
    "#     post_author = structured_post[\"post_author\"]\n",
    "#     post_board = structured_post[\"post_board\"]\n",
    "    \n",
    "    \n",
    "#     if not isinstance(structured_post[\"post_time\"], int):\n",
    "#         structured_post[\"post_time\"] = int(structured_post[\"post_time\"])\n",
    "#     dt = datetime.fromtimestamp(structured_post[\"post_time\"])\n",
    "    \n",
    "#     year = str(dt.year)\n",
    "#     month = str(dt.month)\n",
    "#     day = str(dt.day)\n",
    "#     neg = str(structured_post[\"post_vote\"][\"neg\"])\n",
    "#     pos = str(structured_post[\"post_vote\"][\"pos\"])\n",
    "#     neu = str(structured_post[\"post_vote\"][\"neg\"])\n",
    "    \n",
    "#     title_text = _render_tagged_tuple_to_string(_seg_and_pos([structured_post[\"post_title\"]], ckip))\n",
    "    \n",
    "#     body_text = _render_tagged_tuple_to_string(_seg_and_pos(_preprocessing_content(structured_post[\"post_body\"]), ckip), post_body=True)\n",
    "    \n",
    "#     comments_text = \"\\n\"\n",
    "#     if len(structured_post['comments']) != 0:\n",
    "#         for c in structured_post['comments']:\n",
    "#             comment_author = c[\"author\"]\n",
    "#             comment_type = c[\"type\"]\n",
    "# #             comment_order = c[\"order\"]\n",
    "#             comment_text = _render_tagged_tuple_to_string(_seg_and_pos([c[\"content\"]], ckip))\n",
    "#             comments_text += f\"\"\"\n",
    "# <comment author=\"{comment_author}\" c_type=\"{comment_type}\">\n",
    "# <s>\n",
    "# {comment_text}\n",
    "# </s>\n",
    "# </comment>\n",
    "# \"\"\"\n",
    "    \n",
    "#     return f\"\"\"<TEI.2>\n",
    "#     <teiHeader>\n",
    "#         <metadata name=\"author\">{post_author}</metadata>\n",
    "#         <metadata name=\"post_id\">{post_id}</metadata>\n",
    "#         <metadata name=\"year\">{year}</metadata>\n",
    "#         <metadata name=\"board\">{post_board}</metadata>\n",
    "#     </teiHeader>\n",
    "#     <text>\n",
    "#         <title author=\"{post_author}\">\n",
    "#             <s>\n",
    "#                 {title_text}\n",
    "#             </s>\n",
    "#         </title>\n",
    "#         <body author=\"{post_author}\">\n",
    "#                 {body_text}\n",
    "#         </body>\n",
    "#         {comments_text}\n",
    "#     </text>\n",
    "# </TEI.2>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def json2tei_wrapper(json_path):\n",
    "\n",
    "#     logging.info(\"開始處理: %s\", json_path)\n",
    "\n",
    "#     # 即將要產生的.vrt檔路徑\n",
    "#     tei_path = json_path.with_suffix(\".xml\")\n",
    "\n",
    "#     # 如果該資料夾已經有 .json 檔了就跳過\n",
    "#     if tei_path.is_file():\n",
    "#         logging.info(\"-- 已存在tei(xml)檔: %s\", tei_path)\n",
    "#         return\n",
    "\n",
    "#     try:\n",
    "#         tei_result = json2tei(json_path)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"出問題檔案: {json_path}\")\n",
    "#         print(f\"錯誤訊息: {e}\")\n",
    "#         logging.error(\"-- 執行 json2vrt() 出問題\")\n",
    "#         logging.error(\"-- 錯誤訊息: %s\", e)\n",
    "#         error_class = e.__class__.__name__ #取得錯誤類型\n",
    "#         detail = e.args[0] #取得詳細內容\n",
    "#         cl, exc, tb = sys.exc_info() #取得Call Stack\n",
    "#         lastCallStack = traceback.extract_tb(tb)[-1] #取得Call Stack的最後一筆資料\n",
    "#         fileName = lastCallStack[0] #取得發生的檔案名稱\n",
    "#         lineNum = lastCallStack[1] #取得發生的行號\n",
    "#         funcName = lastCallStack[2] #取得發生的函數名稱\n",
    "#         errMsg = \"File \\\"{}\\\", line {}, in {}: [{}] {}\".format(fileName, lineNum, funcName, error_class, detail)\n",
    "#         print(errMsg)\n",
    "   \n",
    "#     else:\n",
    "# #         if json_result is None:\n",
    "# #             logging.warning(\"-- 空白文!\")\n",
    "# #             return\n",
    "\n",
    "#         with tei_path.open(\"w\") as f:\n",
    "#             f.write(tei_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 斷詞\n",
    "\n",
    "舊版中研院斷詞，請直接使用 `ckipws.py`\n",
    "\n",
    "```\n",
    "from ckipws import CKIP\n",
    "\n",
    "ws = CKIP(\"/home/don/CKIPWS_Linux\")\n",
    "\n",
    "_result = ws.ApplyList([\"我很好\", \"他很好\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 存進mongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_mongo(vrt_file_path, collection):\n",
    "    with open(vrt_file_path, \"r\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if not line.startswith(\"<\") and not line == \"\":\n",
    "                _word_pos = line.split(\"\\t\")\n",
    "                try:\n",
    "                    word = _word_pos[0]\n",
    "                    pos = _word_pos[1]\n",
    "                except:\n",
    "                    print(\"出錯的地方\")\n",
    "                    print(line)\n",
    "                    print(_word_pos)\n",
    "\n",
    "                collection.update_one(\n",
    "                    {\n",
    "                        \"word\": word,\n",
    "                        \"pos\": pos,\n",
    "                    },\n",
    "                    {\n",
    "                        \"$inc\": {\n",
    "                            f\"boards.{board_name}.\": 1,\n",
    "                            \"total\": 1\n",
    "                        }\n",
    "                    },\n",
    "                    upsert=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初步測試"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_path = Path(\"/home/don/test_gossiping_2005_html/Gossiping/2005/20050809_0220_M.1123525242.A.EE4.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(json2tei(Path(\"/home/don/test_gossiping_2005_html/Gossiping/2005/20050809_0220_M.1123525242.A.EE4.json\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for html_path in Path(\"/home/don/test_gossiping_2005_html/\").rglob(\"*.html\"):\n",
    "#     print(html_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dynamic_crawl`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # 剖析指令和參數的部分\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"cmd\", help=\"支援的指令:\\n- list_by_board_by_year <data_directory> (<board_name>)\\n- get_latest_post_timestamp <data_directory> <board_name> \")\n",
    "    parser.add_argument(\"-d\", \"--data-dir\", help=\"檔案所在資料夾路徑\")\n",
    "    parser.add_argument(\"-b\", \"--board\", help=\"板名\")\n",
    "    parser.add_argument(\"-l\", \"--log-to\", help=\".log檔路徑檔名\")\n",
    "    \n",
    "    \n",
    "    # json2vrt才會用到的\n",
    "#     parser.add_argument(\"-c\", \"--ckip-path\", help=\"輸入ckiptagger的模型資料夾路徑\")\n",
    "    parser.add_argument(\"-o\", \"--output-dir\", help=\"輸入要輸出的.vrt檔的完整路徑(含檔名)\")\n",
    "#     parser.add_argument(\"--use-gpu\", help=\"是否使用gpu\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use-mp\", help=\"如要使用多進程，請輸入這個參數\", action=\"store_true\")\n",
    "    \n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        format='%(asctime)s:%(levelname)s:%(message)s',\n",
    "        level=logging.DEBUG,\n",
    "        filename=args.log_to,\n",
    "        filemode='w'\n",
    "    )\n",
    "\n",
    "\n",
    "    logging.info(\"呼叫指令：%s\", args.cmd)\n",
    "    logging.info(\"呼叫參數：%s\", str(args))\n",
    "    \n",
    "    \n",
    "    if args.data_dir is not None:\n",
    "        data_dir = Path(args.data_dir)\n",
    "    \n",
    "    if args.cmd != \"json2vrt\" and args.cmd != \"ws\":\n",
    "        print(\"接收到的參數:\")\n",
    "        print(f\"- 要搜尋的資料夾: {data_dir.resolve()}\")\n",
    "        print(f\"- 要搜尋的版: {args.board}\")\n",
    "        print(\"\")\n",
    "\n",
    "    \n",
    "    if args.cmd.startswith(\"list\"):\n",
    "        ext = args.cmd.split(\"_\")[1]\n",
    "        list_by_board_by_year(data_dir=data_dir, board_name=args.board, ext=ext)\n",
    "        \n",
    "    elif args.cmd == \"get_latest_post_timestamp\":\n",
    "        \n",
    "        latest_timestamp = get_latest_post_timestamp(data_dir, args.board)\n",
    "        logging.info(f\"最新文章的timestamp: {latest_timestamp} ({datetime.fromtimestamp(latest_timestamp)})\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    elif args.cmd == \"html2json\":\n",
    "        \n",
    "        # 計時開始\n",
    "        t1 = timeit.default_timer()\n",
    "        \n",
    "        # 如果有指定 --board 參數\n",
    "        if args.board is not None:\n",
    "            data_dir = data_dir / args.board \n",
    "        \n",
    "        print(data_dir)\n",
    "        # 數總檔案數\n",
    "        total_processed_files = len(list(data_dir.glob(\"**/*.html\")))\n",
    "        print(total_processed_files)\n",
    "        \n",
    "        # 如果使用多進程\n",
    "        if args.use_mp:\n",
    "\n",
    "            cpu_count = mp.cpu_count()\n",
    "            pool = mp.Pool(cpu_count)\n",
    "\n",
    "            pool.imap_unordered(html2json_wrapper, data_dir.rglob(\"*.html\"))\n",
    "\n",
    "            pool.close()\n",
    "            pool.join()\n",
    "        \n",
    "        \n",
    "        # 如果不使用多進程\n",
    "        else:\n",
    "            for html_path in data_dir.rglob(\"*.html\"):\n",
    "                html2json_wrapper(html_path)\n",
    "        \n",
    "        # 計時屆結束  \n",
    "        t2 = timeit.default_timer()\n",
    "        \n",
    "        print(\"=================\")\n",
    "        print(f\"總處理檔案數: {total_processed_files}\")\n",
    "        print(f\"總處理時間: {t2 -t1} 秒\")\n",
    "        logging.info(\"=================\")\n",
    "        logging.info(f\"總處理檔案數: {total_processed_files}\")\n",
    "        logging.info(f\"總處理時間: {t2 -t1} 秒\")\n",
    "    \n",
    "    \n",
    "    elif args.cmd == \"json2tei\":\n",
    "        \n",
    "#         ckipws = None\n",
    "#         initial()\n",
    "        \n",
    "        # 數總檔案數\n",
    "        total_processed_files = len(list(data_dir.glob(\"**/*.json\")))\n",
    "        \n",
    "        # 開始計時\n",
    "        t1 = timeit.default_timer()\n",
    "\n",
    "\n",
    "        # 使用多進程\n",
    "        if args.use_mp:\n",
    "            cpu_count = mp.cpu_count()\n",
    "            pool = mp.Pool(cpu_count)\n",
    "            pool.imap_unordered(json2tei_wrapper, data_dir.rglob(\"*.json\"))\n",
    "            \n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "        # 不使用多進程\n",
    "        else:\n",
    "            \n",
    "            for json_path in data_dir.rglob(\"*.json\"):\n",
    "                json2tei_wrapper(json_path)\n",
    "\n",
    "        # 計時結束\n",
    "        t2 = timeit.default_timer()   \n",
    "        \n",
    "        print(\"=================\")\n",
    "        print(f\"總處理檔案數: {total_processed_files}\")\n",
    "        print(f\"總處理時間: {t2 - t1} 秒\")\n",
    "        logging.info(\"=================\")\n",
    "        logging.info(f\"總處理檔案數: {total_processed_files}\")\n",
    "        logging.info(f\"總處理時間: {t2 - t1} 秒\")\n",
    "\n",
    "    elif args.cmd == \"json2vrt\":\n",
    "        \n",
    "        ckipws = None\n",
    "        initial()\n",
    "        \n",
    "        # 數總檔案數\n",
    "        total_processed_files = len(list(data_dir.glob(\"**/*.json\")))\n",
    "        \n",
    "        # 開始計時\n",
    "        t1 = timeit.default_timer()\n",
    "\n",
    "\n",
    "        # 使用多進程\n",
    "        if args.use_mp:\n",
    "            cpu_count = mp.cpu_count()\n",
    "            pool = mp.Pool(cpu_count)\n",
    "            pool.imap_unordered(json2vrt_wrapper, data_dir.rglob(\"*.json\"))\n",
    "            \n",
    "            pool.close()\n",
    "            pool.join()\n",
    "            \n",
    "        # 不使用多進程\n",
    "        else:\n",
    "            \n",
    "            for json_path in data_dir.rglob(\"*.json\"):\n",
    "                json2vrt_wrapper(json_path)\n",
    "\n",
    "        # 計時結束\n",
    "        t2 = timeit.default_timer()   \n",
    "        \n",
    "        print(\"=================\")\n",
    "        print(f\"總處理檔案數: {total_processed_files}\")\n",
    "        print(f\"總處理時間: {t2 - t1} 秒\")\n",
    "        logging.info(\"=================\")\n",
    "        logging.info(f\"總處理檔案數: {total_processed_files}\")\n",
    "        logging.info(f\"總處理時間: {t2 - t1} 秒\")\n",
    "    \n",
    "    elif args.cmd == \"ws\":\n",
    "        \n",
    "        \n",
    "        def word_segmentation_ms_wrapper(list_of_sentences):\n",
    "            ckipws = get_ckipws()\n",
    "            a = ckipws.ApplyList(list_of_sentences)\n",
    "            return a\n",
    "            \n",
    "#         lib = '/home/don/CKIPWS_Linux/lib/libWordSeg.so'\n",
    "#         # 指定 CKIPWS 的設定檔\n",
    "#         inifile = '/home/don/CKIPWS_Linux/ws.ini'\n",
    "#         # 進行 CKIPWS 初始化的動作\n",
    "#         initial(lib, inifile)\n",
    "\n",
    "        \n",
    "        t1 = timeit.default_timer()\n",
    "        \n",
    "        Result = word_segmentation_ms_wrapper(['這是一個測試的測試的'] * 1000)\n",
    "\n",
    "        \n",
    "        t2 = timeit.default_timer()\n",
    "        print(t2 - t1)\n",
    "        \n",
    "        # 結果在 Result 中\n",
    "#         print (Result)\n",
    "    \n",
    "    elif args.cmd == \"dynamic_crawl\":\n",
    "        \n",
    "        now = datetime.now()\n",
    "        now_ymd_str = now.strftime(\"%Y_%m_%d\")\n",
    "        session_name = f\"{now_ymd_str}_ptt_crawl\"\n",
    "        \n",
    "        server = libtmux.Server()\n",
    "        new_session = server.new_session(\n",
    "            session_name=session_name,\n",
    "            attach=False,\n",
    "            start_directory=\"/home/don\",\n",
    "        )\n",
    "        \n",
    "        for board_path in data_dir.iterdir():\n",
    "            board = board_path.name\n",
    "            latest_timestamp = get_latest_post_timestamp(data_dir, board)\n",
    "            \n",
    "            logging.info(f\"{board} 版: {datetime.fromtimestamp(latest_timestamp)}\")\n",
    "        \n",
    "            window = new_session.new_window(attach=False, window_name=f\"{board}\")\n",
    "            pane = window.split_window(attach=False)\n",
    "            pane.send_keys(\"cd /home/don/ptt_python_crawler\")\n",
    "            pane.send_keys(f\"scrapy crawl ptt_article -a boards={board} -a since={latest_timestamp} --logfile /home/don/log/{now_ymd_str}_{board} -a data_dir={str(data_dir)}\")\n",
    "#             pane.send_keys(f\"python3 ptt_helper.py list_json -d /home/don/ptt_json_rawdata -b {board}\")\n",
    "\n",
    "            # 跑完後直接進行斷詞\n",
    "            pane.send_keys(f\"python3 /home/don/ptt_helper.py json2vrt -d {str(data_dir)} --use-mp\")\n",
    "    \n",
    "    elif args.cmd == \"reduce_to_one_vrt\":\n",
    "        \n",
    "        for board_path in data_dir.iterdir():\n",
    "            board = board_path.name\n",
    "            \n",
    "            output_dir = Path(args.output_dir)\n",
    "            output_board_file = output_dir / f\"{board}.vrt\"\n",
    "            \n",
    "            with open(output_board_file, \"w\") as output_file:\n",
    "                \n",
    "                \n",
    "                for individual_vrt_file in board_path.rglob(\"*.vrt\"):\n",
    "                    \n",
    "                    with open(individual_vrt_file, \"r\") as f:\n",
    "                        output_file.write(f.read() + \"\\n\")\n",
    "        \n",
    "    elif args.cmd == \"save_lexical_items_to_mongo\":\n",
    "        uri = \"mongodb://ntulope:lopelopelopelope@localhost:27014/ptt?authSource=admin\"\n",
    "#         client = MongoClient(uri)\n",
    "\n",
    "#         ptt_db = client.ptt\n",
    "#         lexical_item_collection = ptt_db.lexical_item\n",
    "\n",
    "\n",
    "\n",
    "#         for board_path in data_dir.iterdir():\n",
    "#             board = board_path.name\n",
    "            \n",
    "#             save_to_mongo( vrt_file_path, lexical_item_collection)\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"不存在這個指令！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!jupyter nbconvert --to script ptt_helper.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
